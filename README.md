# Covid-19-Analysis
Create A Data Pipeline Based On Messaging Using PySpark And Hive

[Link to Covid-19 Dataset]{https://api.covid19api.com/summary}

In this project Covid-19 Data is being visualized to compare the deaths by Countries in between Dates, Average of Total Deaths by Countries by Dates, Average of Countries total cases recovered by Date etc.

Simulate a complex real-world data pipeline based on messaging. This project is deployed using the following tech stack - NiFi, PySpark, Hive, HDFS, Kafka, Airflow, Tableau and AWS QuickSight.

• End-to-end implementation of Big data pipeline on AWS • Big Data and data pipeline building and automation of the processes • Real time streaming data import from external API using NiFi • Parsing of the complex Json data into csv using NiFi and storing in HDFS • Encryption of one of the PII fields in the data using NiFi • Sending parsed data to Kafka for data processing using PySpark and writing the data to output Kafka topic • Consume data from Kafka and store processed data in HDFS • Create a Hive external table on top of the data stored in HDFS followed by data query • Data cleaning, transformation, storing in the data lake • Visualization of the key performance indicators by using top end industry big data tools • Data flow orchestration for continuous integration of the data pipeline using Airflow • Visualization of the data using AWS QuickSight and Tableau.
